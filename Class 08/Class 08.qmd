---
title: "Class 8: PCA mini project"
author: "Yaniv Iny (PID:18090586)"
format: pdf
---

Today we will do a complete analysis of some breast cancer biopsy data but first let's revisit the main PCA function in R `prcomp()` and see what `scale=TRUE/FALSE does. 

```{r}
head(mtcars)
```

Find the mean value per columnof this dataset

```{r}
apply(mtcars, 2, mean)
```

```{r}
apply(mtcars, 2, sd)
```

It is clear "disp" and "hp" have the highest mean values and the highest standard deviation here. They will dominate any analysis I do on this dataset. Let's see.

```{r}
pc.noscale <- prcomp(mtcars, scale = FALSE)
pc.scale <- prcomp(mtcars, scale = TRUE)
```


```{r}
biplot(pc.noscale)
```
 
```{r}
pc.noscale$rotation[,1]
```
 
 plot the loading's
 
```{r}
library(ggplot2)

r1 <- as.data.frame(pc.noscale$rotation)
r1$names <- rownames(pc.noscale$rotation)

ggplot(r1) +
  aes(PC1, names) +
  geom_col()
```
 
```{r}
library(ggplot2)

r2 <- as.data.frame(pc.scale$rotation)
r2$names <- rownames(pc.scale$rotation)

ggplot(r2) +
  aes(PC1, names) +
  geom_col()
```
 
```{r}
biplot(pc.scale)
```
 
 > **Take Home**: Generally we always want to set `scale=TRUE` when we do this type of analysis to avoid our analysis being dominated by individual variables with the largest variance just due to their unit of measurment. 
 
 # FNA breast cancer data 
 
 load the data into R
 
```{r}
wisc.df <- read.csv("WisconsinCancer.csv")

head(wisc.df)
```
 
> Q1. How many observations are in this dataset?

```{r}
nrow(wisc.df)
```


> Q2. How many of the observations have a malignant diagnosis?

```{r}
sum(wisc.df$diagnosis =="M")
```

The `table()` function is super useful here 

```{r}
table(wisc.df$diagnosis)
```



 > Q3. How many variables/features in the data are suffixed with _mean?
 
 
```{r}
ncol(wisc.df)
```
```{r}
colnames(wisc.df)
```
 
 A useful function for this is `grep()`
 
```{r}
grep("_mean", colnames(wisc.df))
```

```{r}
length(grep("_mean", colnames(wisc.df)))
```

 Before we go any further we need to exclude the diagnosis column from any future analysis - this tells us whether a sample to cancer or non-cancer.
 
```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
head(diagnosis)
```
 
```{r}
wisc.data <- wisc.df[,-1]
```
 
Lets see if we can cluster the `wisc.data` to find some structure in the dataset. 

```{r}
hc <- hclust(dist(wisc.data))
plot(hc)
```
# Principle Component Analysis (PCA)

```{r}
wisc.data <- wisc.data[sapply(wisc.data, is.numeric)]
```

```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE)
summary(wisc.pr)
```
> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

The proportion of variance that is captured is 0.4427
> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

PC 1-3 is required to describe at least 70% of the orignal variance data 

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

PC 1-7 describes at least 90% of the orgiinal variance

Plot this data 
```{r}
biplot(wisc.pr)
```
 > Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
 
 The first thing that I notice about this plot is how clustered together everything is. This makes the plot extremely hard to understand and can not be read accurately to retrieve data from it. 
 
 This biplot sucks! we need to build our own PCA score plot of PC1 vs PC2
 
```{r}
attributes(wisc.pr)
```
 
```{r}
head(wisc.pr$x)
```
 
Plot of PC1 vs PC2 the first two columns 
>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

Immediately after creating this plot we are able to see that it is much more clear and easier to understand the data from it. We see the difference between the red(malignant), and the black(benign)
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```


Make a ggplot version of this score plot

Data frame 
```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
```

Load ggplot 
```{r}
library(ggplot2)
```
Make a scatter plot
```{r}
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

Variance Explained

We want to find out if there is an elbow in the amount of variance, to calculate this we will write some code. 

Variance of each component

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Variance by principal component 

```{r}
pve <- (pr.var)/ (sum(pr.var))
```

Plotting variance explained for each principle component

```{r}
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
Alternative scree plot of the same data, note data driven y-axis

```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```
 
GGplot example of this graph 

```{r}
## ggplot based graph
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```
> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean", 1]
```

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

The miniimum number of principle components is 5

##Hierarchical Clustering

```{r}
data.scaled <- scale(wisc.data)
```

Calculate the (Euclidean) distances

```{r}
data.dist <- dist(data.scaled)
```

 hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.
 
```{r}
wisc.hclust <- hclust(data.dist, method="complete")
```
 
> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

At 19 the clustering tree has 4 clusters 

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, (k=4))
```

We can use the table() function to compare the cluster membership to the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

Changing the number of clusters (k) can improve how well they match the actual diagnoses. Using k=2 works well since there are two main groups (malignant and benign), but k=3 or 4 might show more details. Testing different k values helps find the best match.

>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

The best method depends on how well the clusters match the actual diagnoses. The "complete" method is good at keeping similar cases together, but "ward.D2" can create more balanced clusters. Testing different methods helps find the best one.



## Clustering in PC space

```{r}
hc <- hclust(dist(wisc.pr$x[,1:2]), method="ward.D2")

plot(hc)
abline(h=70, col="red")
```
Cluster membership vector

```{r}
grps <- cutree(hc, h=70)
table(grps)
```


```{r}
table(diagnosis)
```

Cross table to see how my clustering groups correspond to the expert diagnosis vector of M and B values.

```{r}
table(grps, diagnosis)
```
Positive would => cancer M 
Negative => non-cancer B 

True = cluster/grp 1
False = grp 2 

True Positive 177
False Positive 18
True Negative 339
False Negative 35

We can use our PCA results (wis.pr) to make prediections on new unseen data. 

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```
```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

# Plot using our re-ordered factor 
```{r}
plot(wisc.pr$x[,1:2], col=g)
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

We checked how well the four clusters match the diagnoses. The clusters separate malignant and benign samples fairly well, but it's not perfect. We can look at the table for true positives and true negatives.

##                        diagnosis
## wisc.pr.hclust.clusters   B   M
##                       1  28 188
##                       2 329  24

>Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

The k-means and hierarchical clustering models both show some success in separating the diagnoses, but neither perfectly matches the true labels. By examining the tables, we can see how each model's clusters align with benign (B) and malignant (M) diagnoses.

##    diagnosis
##       B   M
##   1  14 175
##   2 343  37
##                     diagnosis
## wisc.hclust.clusters   B   M
##                    1  12 165
##                    2   2   5
##                    3 343  40
##                    4   0   2

## Sensitivty/Specifity

Sensitivity refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

We compare the clusters to the actual diagnoses. The clustering method with the highest specificity correctly identifies benign samples, while the one with the highest sensitivity better detects malignant samples.

## Prediction 
We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

 The ones closer to the malignant group (with higher PC1 and PC2 values in that direction) should be prioritized for follow-up. in our case it would be patient 1.
 